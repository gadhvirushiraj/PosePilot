{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_class = pd.read_csv('/Users/priyanshdesai07/Plaksha/MLPR/Project/YogaPal/feature_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(feature_class, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>1.215251</td>\n",
       "      <td>178.701795</td>\n",
       "      <td>160.780908</td>\n",
       "      <td>163.525199</td>\n",
       "      <td>45.808222</td>\n",
       "      <td>46.273112</td>\n",
       "      <td>10.221909</td>\n",
       "      <td>9.778649</td>\n",
       "      <td>157.887718</td>\n",
       "      <td>166.323635</td>\n",
       "      <td>169.415868</td>\n",
       "      <td>18.959750</td>\n",
       "      <td>130.278140</td>\n",
       "      <td>159.827422</td>\n",
       "      <td>157.418498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>18.200794</td>\n",
       "      <td>165.186117</td>\n",
       "      <td>175.526671</td>\n",
       "      <td>142.298601</td>\n",
       "      <td>4.457796</td>\n",
       "      <td>84.511830</td>\n",
       "      <td>125.215859</td>\n",
       "      <td>46.556846</td>\n",
       "      <td>25.884185</td>\n",
       "      <td>175.847411</td>\n",
       "      <td>165.962661</td>\n",
       "      <td>151.096085</td>\n",
       "      <td>18.015458</td>\n",
       "      <td>175.188548</td>\n",
       "      <td>11.506032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>155.079335</td>\n",
       "      <td>159.502772</td>\n",
       "      <td>15.871008</td>\n",
       "      <td>16.482777</td>\n",
       "      <td>8.133653</td>\n",
       "      <td>6.152547</td>\n",
       "      <td>165.493384</td>\n",
       "      <td>151.505819</td>\n",
       "      <td>95.095715</td>\n",
       "      <td>166.015674</td>\n",
       "      <td>168.108538</td>\n",
       "      <td>33.614765</td>\n",
       "      <td>0.374404</td>\n",
       "      <td>24.680920</td>\n",
       "      <td>24.744958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>175.251568</td>\n",
       "      <td>0.866504</td>\n",
       "      <td>132.838685</td>\n",
       "      <td>131.491195</td>\n",
       "      <td>179.465255</td>\n",
       "      <td>1.909601</td>\n",
       "      <td>155.727521</td>\n",
       "      <td>143.300954</td>\n",
       "      <td>64.406778</td>\n",
       "      <td>166.432626</td>\n",
       "      <td>163.661625</td>\n",
       "      <td>13.109031</td>\n",
       "      <td>147.289609</td>\n",
       "      <td>84.031104</td>\n",
       "      <td>89.514661</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>62.520758</td>\n",
       "      <td>124.881086</td>\n",
       "      <td>31.763892</td>\n",
       "      <td>0.235632</td>\n",
       "      <td>115.545881</td>\n",
       "      <td>179.343359</td>\n",
       "      <td>151.331745</td>\n",
       "      <td>39.914026</td>\n",
       "      <td>59.353298</td>\n",
       "      <td>11.877250</td>\n",
       "      <td>5.107120</td>\n",
       "      <td>142.927908</td>\n",
       "      <td>40.430047</td>\n",
       "      <td>169.410153</td>\n",
       "      <td>1.471897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>9.507434</td>\n",
       "      <td>171.365004</td>\n",
       "      <td>18.399265</td>\n",
       "      <td>162.441225</td>\n",
       "      <td>144.322879</td>\n",
       "      <td>34.511114</td>\n",
       "      <td>161.095602</td>\n",
       "      <td>17.817913</td>\n",
       "      <td>63.224838</td>\n",
       "      <td>14.239353</td>\n",
       "      <td>169.471597</td>\n",
       "      <td>169.913273</td>\n",
       "      <td>4.747327</td>\n",
       "      <td>15.602277</td>\n",
       "      <td>167.087285</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>173.429903</td>\n",
       "      <td>24.209763</td>\n",
       "      <td>130.057578</td>\n",
       "      <td>127.064989</td>\n",
       "      <td>3.657907</td>\n",
       "      <td>179.579783</td>\n",
       "      <td>118.024926</td>\n",
       "      <td>148.850335</td>\n",
       "      <td>28.375701</td>\n",
       "      <td>164.403740</td>\n",
       "      <td>163.707278</td>\n",
       "      <td>176.758133</td>\n",
       "      <td>145.793326</td>\n",
       "      <td>90.431421</td>\n",
       "      <td>76.210872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>174.797692</td>\n",
       "      <td>176.906845</td>\n",
       "      <td>20.499403</td>\n",
       "      <td>18.538210</td>\n",
       "      <td>18.848601</td>\n",
       "      <td>7.770495</td>\n",
       "      <td>160.309992</td>\n",
       "      <td>11.280125</td>\n",
       "      <td>44.518578</td>\n",
       "      <td>165.286435</td>\n",
       "      <td>176.749668</td>\n",
       "      <td>37.511165</td>\n",
       "      <td>144.540852</td>\n",
       "      <td>37.147992</td>\n",
       "      <td>33.015327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>175.405444</td>\n",
       "      <td>1.614313</td>\n",
       "      <td>177.846870</td>\n",
       "      <td>174.312588</td>\n",
       "      <td>179.265651</td>\n",
       "      <td>178.057935</td>\n",
       "      <td>153.701932</td>\n",
       "      <td>42.345202</td>\n",
       "      <td>73.455371</td>\n",
       "      <td>176.878066</td>\n",
       "      <td>174.203367</td>\n",
       "      <td>32.250924</td>\n",
       "      <td>111.198382</td>\n",
       "      <td>175.112156</td>\n",
       "      <td>168.264229</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>59.012702</td>\n",
       "      <td>118.835776</td>\n",
       "      <td>21.270091</td>\n",
       "      <td>158.445827</td>\n",
       "      <td>149.757344</td>\n",
       "      <td>26.540320</td>\n",
       "      <td>156.782909</td>\n",
       "      <td>22.196073</td>\n",
       "      <td>60.858998</td>\n",
       "      <td>13.238733</td>\n",
       "      <td>170.059959</td>\n",
       "      <td>155.111662</td>\n",
       "      <td>27.852332</td>\n",
       "      <td>18.131835</td>\n",
       "      <td>162.020366</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1          f2          f3          f4          f5          f6  \\\n",
       "916     1.215251  178.701795  160.780908  163.525199   45.808222   46.273112   \n",
       "261    18.200794  165.186117  175.526671  142.298601    4.457796   84.511830   \n",
       "607   155.079335  159.502772   15.871008   16.482777    8.133653    6.152547   \n",
       "1331  175.251568    0.866504  132.838685  131.491195  179.465255    1.909601   \n",
       "240    62.520758  124.881086   31.763892    0.235632  115.545881  179.343359   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1130    9.507434  171.365004   18.399265  162.441225  144.322879   34.511114   \n",
       "1294  173.429903   24.209763  130.057578  127.064989    3.657907  179.579783   \n",
       "860   174.797692  176.906845   20.499403   18.538210   18.848601    7.770495   \n",
       "1459  175.405444    1.614313  177.846870  174.312588  179.265651  178.057935   \n",
       "1126   59.012702  118.835776   21.270091  158.445827  149.757344   26.540320   \n",
       "\n",
       "              f7          f8          f9         f10         f11         f12  \\\n",
       "916    10.221909    9.778649  157.887718  166.323635  169.415868   18.959750   \n",
       "261   125.215859   46.556846   25.884185  175.847411  165.962661  151.096085   \n",
       "607   165.493384  151.505819   95.095715  166.015674  168.108538   33.614765   \n",
       "1331  155.727521  143.300954   64.406778  166.432626  163.661625   13.109031   \n",
       "240   151.331745   39.914026   59.353298   11.877250    5.107120  142.927908   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1130  161.095602   17.817913   63.224838   14.239353  169.471597  169.913273   \n",
       "1294  118.024926  148.850335   28.375701  164.403740  163.707278  176.758133   \n",
       "860   160.309992   11.280125   44.518578  165.286435  176.749668   37.511165   \n",
       "1459  153.701932   42.345202   73.455371  176.878066  174.203367   32.250924   \n",
       "1126  156.782909   22.196073   60.858998   13.238733  170.059959  155.111662   \n",
       "\n",
       "             f13         f14         f15  label  \n",
       "916   130.278140  159.827422  157.418498      1  \n",
       "261    18.015458  175.188548   11.506032      0  \n",
       "607     0.374404   24.680920   24.744958      1  \n",
       "1331  147.289609   84.031104   89.514661      2  \n",
       "240    40.430047  169.410153    1.471897      0  \n",
       "...          ...         ...         ...    ...  \n",
       "1130    4.747327   15.602277  167.087285      3  \n",
       "1294  145.793326   90.431421   76.210872      2  \n",
       "860   144.540852   37.147992   33.015327      1  \n",
       "1459  111.198382  175.112156  168.264229      2  \n",
       "1126   27.852332   18.131835  162.020366      3  \n",
       "\n",
       "[1605 rows x 16 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>175.118997</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>155.638956</td>\n",
       "      <td>156.817359</td>\n",
       "      <td>38.165912</td>\n",
       "      <td>40.165465</td>\n",
       "      <td>163.972336</td>\n",
       "      <td>169.664597</td>\n",
       "      <td>71.105572</td>\n",
       "      <td>163.874026</td>\n",
       "      <td>165.593845</td>\n",
       "      <td>179.879761</td>\n",
       "      <td>179.274196</td>\n",
       "      <td>157.197418</td>\n",
       "      <td>158.587304</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>174.895982</td>\n",
       "      <td>178.247573</td>\n",
       "      <td>23.558653</td>\n",
       "      <td>27.068620</td>\n",
       "      <td>5.794607</td>\n",
       "      <td>3.560919</td>\n",
       "      <td>169.409627</td>\n",
       "      <td>172.080409</td>\n",
       "      <td>48.197755</td>\n",
       "      <td>169.375433</td>\n",
       "      <td>169.207910</td>\n",
       "      <td>3.198240</td>\n",
       "      <td>151.252671</td>\n",
       "      <td>38.128247</td>\n",
       "      <td>40.427285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>20.776743</td>\n",
       "      <td>21.886164</td>\n",
       "      <td>163.834368</td>\n",
       "      <td>164.476309</td>\n",
       "      <td>174.400376</td>\n",
       "      <td>165.532175</td>\n",
       "      <td>168.368745</td>\n",
       "      <td>5.316406</td>\n",
       "      <td>122.069725</td>\n",
       "      <td>19.845749</td>\n",
       "      <td>21.754202</td>\n",
       "      <td>162.488441</td>\n",
       "      <td>150.298751</td>\n",
       "      <td>158.001828</td>\n",
       "      <td>155.637952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>174.815875</td>\n",
       "      <td>172.560259</td>\n",
       "      <td>135.341165</td>\n",
       "      <td>134.833495</td>\n",
       "      <td>2.616912</td>\n",
       "      <td>2.960485</td>\n",
       "      <td>157.999656</td>\n",
       "      <td>158.809840</td>\n",
       "      <td>0.222880</td>\n",
       "      <td>164.858100</td>\n",
       "      <td>165.269851</td>\n",
       "      <td>8.731413</td>\n",
       "      <td>172.068248</td>\n",
       "      <td>98.714861</td>\n",
       "      <td>97.882400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2.990669</td>\n",
       "      <td>9.457863</td>\n",
       "      <td>156.513223</td>\n",
       "      <td>156.412224</td>\n",
       "      <td>176.617344</td>\n",
       "      <td>176.094287</td>\n",
       "      <td>175.984970</td>\n",
       "      <td>177.264333</td>\n",
       "      <td>175.358181</td>\n",
       "      <td>4.858060</td>\n",
       "      <td>6.161580</td>\n",
       "      <td>22.489112</td>\n",
       "      <td>154.994505</td>\n",
       "      <td>146.578357</td>\n",
       "      <td>145.050271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>178.110311</td>\n",
       "      <td>177.971681</td>\n",
       "      <td>15.410488</td>\n",
       "      <td>14.949850</td>\n",
       "      <td>14.223085</td>\n",
       "      <td>12.933281</td>\n",
       "      <td>5.133310</td>\n",
       "      <td>2.416997</td>\n",
       "      <td>135.820531</td>\n",
       "      <td>166.042353</td>\n",
       "      <td>167.766301</td>\n",
       "      <td>158.430762</td>\n",
       "      <td>128.191435</td>\n",
       "      <td>29.028950</td>\n",
       "      <td>27.812121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>172.343225</td>\n",
       "      <td>172.516179</td>\n",
       "      <td>126.855976</td>\n",
       "      <td>125.770005</td>\n",
       "      <td>2.433488</td>\n",
       "      <td>2.700150</td>\n",
       "      <td>177.688772</td>\n",
       "      <td>163.482507</td>\n",
       "      <td>84.496017</td>\n",
       "      <td>162.627240</td>\n",
       "      <td>162.468923</td>\n",
       "      <td>18.878535</td>\n",
       "      <td>172.149445</td>\n",
       "      <td>86.287612</td>\n",
       "      <td>88.149528</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>35.093302</td>\n",
       "      <td>141.382119</td>\n",
       "      <td>18.347092</td>\n",
       "      <td>162.952727</td>\n",
       "      <td>160.231747</td>\n",
       "      <td>16.235959</td>\n",
       "      <td>147.423155</td>\n",
       "      <td>32.272845</td>\n",
       "      <td>53.614488</td>\n",
       "      <td>13.567337</td>\n",
       "      <td>166.176058</td>\n",
       "      <td>166.744006</td>\n",
       "      <td>16.474721</td>\n",
       "      <td>21.386698</td>\n",
       "      <td>158.997489</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>149.799049</td>\n",
       "      <td>26.135202</td>\n",
       "      <td>145.989700</td>\n",
       "      <td>20.975982</td>\n",
       "      <td>30.125452</td>\n",
       "      <td>148.387807</td>\n",
       "      <td>39.672071</td>\n",
       "      <td>143.255874</td>\n",
       "      <td>142.400825</td>\n",
       "      <td>167.309143</td>\n",
       "      <td>14.875696</td>\n",
       "      <td>68.457215</td>\n",
       "      <td>136.717739</td>\n",
       "      <td>149.855623</td>\n",
       "      <td>27.000702</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>3.052402</td>\n",
       "      <td>3.483043</td>\n",
       "      <td>161.351132</td>\n",
       "      <td>159.755385</td>\n",
       "      <td>178.495228</td>\n",
       "      <td>172.127860</td>\n",
       "      <td>162.759849</td>\n",
       "      <td>5.589880</td>\n",
       "      <td>97.999395</td>\n",
       "      <td>11.630663</td>\n",
       "      <td>12.108404</td>\n",
       "      <td>34.905954</td>\n",
       "      <td>151.582802</td>\n",
       "      <td>151.932284</td>\n",
       "      <td>146.718838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1          f2          f3          f4          f5          f6  \\\n",
       "1960  175.118997    0.048210  155.638956  156.817359   38.165912   40.165465   \n",
       "526   174.895982  178.247573   23.558653   27.068620    5.794607    3.560919   \n",
       "393    20.776743   21.886164  163.834368  164.476309  174.400376  165.532175   \n",
       "1402  174.815875  172.560259  135.341165  134.833495    2.616912    2.960485   \n",
       "433     2.990669    9.457863  156.513223  156.412224  176.617344  176.094287   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "938   178.110311  177.971681   15.410488   14.949850   14.223085   12.933281   \n",
       "1326  172.343225  172.516179  126.855976  125.770005    2.433488    2.700150   \n",
       "1138   35.093302  141.382119   18.347092  162.952727  160.231747   16.235959   \n",
       "1037  149.799049   26.135202  145.989700   20.975982   30.125452  148.387807   \n",
       "654     3.052402    3.483043  161.351132  159.755385  178.495228  172.127860   \n",
       "\n",
       "              f7          f8          f9         f10         f11         f12  \\\n",
       "1960  163.972336  169.664597   71.105572  163.874026  165.593845  179.879761   \n",
       "526   169.409627  172.080409   48.197755  169.375433  169.207910    3.198240   \n",
       "393   168.368745    5.316406  122.069725   19.845749   21.754202  162.488441   \n",
       "1402  157.999656  158.809840    0.222880  164.858100  165.269851    8.731413   \n",
       "433   175.984970  177.264333  175.358181    4.858060    6.161580   22.489112   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "938     5.133310    2.416997  135.820531  166.042353  167.766301  158.430762   \n",
       "1326  177.688772  163.482507   84.496017  162.627240  162.468923   18.878535   \n",
       "1138  147.423155   32.272845   53.614488   13.567337  166.176058  166.744006   \n",
       "1037   39.672071  143.255874  142.400825  167.309143   14.875696   68.457215   \n",
       "654   162.759849    5.589880   97.999395   11.630663   12.108404   34.905954   \n",
       "\n",
       "             f13         f14         f15  label  \n",
       "1960  179.274196  157.197418  158.587304      5  \n",
       "526   151.252671   38.128247   40.427285      1  \n",
       "393   150.298751  158.001828  155.637952      1  \n",
       "1402  172.068248   98.714861   97.882400      2  \n",
       "433   154.994505  146.578357  145.050271      1  \n",
       "...          ...         ...         ...    ...  \n",
       "938   128.191435   29.028950   27.812121      1  \n",
       "1326  172.149445   86.287612   88.149528      2  \n",
       "1138   16.474721   21.386698  158.997489      3  \n",
       "1037  136.717739  149.855623   27.000702      3  \n",
       "654   151.582802  151.932284  146.718838      1  \n",
       "\n",
       "[402 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(hidden_size, 50)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(50, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 15  \n",
    "hidden_size = 25\n",
    "num_classes = 6  \n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimize = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_torch = torch.tensor(train_df.drop('label',axis = 1).values, dtype=torch.float32)\n",
    "label_torch = torch.tensor(train_df['label'].values,dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_torch_test = torch.tensor(test_df.drop('label',axis = 1).values, dtype=torch.float32)\n",
    "label_torch_test = torch.tensor(test_df['label'].values,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(feature_torch, label_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(feature_torch_test, label_torch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "shuffle = True\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "shuffle = False   \n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accurate(correct, total, pred, all_label):\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "            all_label.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return correct, total\n",
    "\n",
    "    # accuracy = 100 * correct / total\n",
    "    # print(f\"Accuracy on the test data: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: 80.34825870646766%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "pred = []\n",
    "all_label = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for epoch in range(20):\n",
    "    # print(f\"epoch: {epoch}/20\")\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        optimize.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss1 = loss(outputs, labels)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss1.backward()  # Backpropagation\n",
    "        optimize.step()  # Update weights\n",
    "\n",
    "correct1, total1 = accurate(correct, total, pred, all_label)\n",
    "    \n",
    "    # print('loss: ', loss1.item())\n",
    "    # accuracy = 100 * correct1 / total1\n",
    "    # print(f\"Accuracy on the test data: {accuracy}%\")\n",
    "\n",
    "accuracy = 100 * correct1 / total1\n",
    "print(f\"Accuracy on the test data: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 68   0   3   0   2   0]\n",
      " [  2 122   1   0   0   0]\n",
      " [  1   1  91   0   0   0]\n",
      " [ 37   3   1   0   0   0]\n",
      " [  0   2   3   0  27   1]\n",
      " [  7   2  11   0   2  15]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_label, pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72        73\n",
      "           1       0.94      0.98      0.96       125\n",
      "           2       0.83      0.98      0.90        93\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.87      0.82      0.84        33\n",
      "           5       0.94      0.41      0.57        37\n",
      "\n",
      "    accuracy                           0.80       402\n",
      "   macro avg       0.69      0.68      0.66       402\n",
      "weighted avg       0.75      0.80      0.76       402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(all_label, pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
